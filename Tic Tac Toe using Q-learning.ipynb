{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa1f09d4-0913-47fd-aee3-b58930a3b4b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Complete! Q-Table Saved.\n",
      "  |   |  \n",
      "  |   |  \n",
      "  |   |   \n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "import pickle\n",
    "\n",
    "class TicTacToeQLearning:\n",
    "    def __init__(self, alpha=0.1, gamma=0.9, epsilon=0.2):\n",
    "        self.q_table = {}\n",
    "        self.alpha, self.gamma, self.epsilon = alpha, gamma, epsilon\n",
    "        self.state_history = []\n",
    "\n",
    "    def get_q_value(self, state, action):\n",
    "        return self.q_table.get((tuple(state), action), 0.0)\n",
    "\n",
    "    def choose_action(self, board, available_moves):\n",
    "        if random.uniform(0, 1) < self.epsilon:\n",
    "            return random.choice(available_moves)\n",
    "        q_values = {move: self.get_q_value(board, move) for move in available_moves}\n",
    "        return max(q_values, key=q_values.get)\n",
    "\n",
    "    def update_q_table(self, reward):\n",
    "        for state, action in reversed(self.state_history):\n",
    "            self.q_table[(tuple(state), action)] = self.get_q_value(state, action) + self.alpha * (reward - self.get_q_value(state, action))\n",
    "            reward *= self.gamma\n",
    "        self.state_history = []\n",
    "\n",
    "    def save_q_table(self, filename='q_table.pkl'):\n",
    "        with open(filename, 'wb') as f:\n",
    "            pickle.dump(self.q_table, f)\n",
    "\n",
    "    def load_q_table(self, filename='q_table.pkl'):\n",
    "        with open(filename, 'rb') as f:\n",
    "            self.q_table = pickle.load(f)\n",
    "\n",
    "def check_winner(board, player):\n",
    "    return any(all(board[i] == player for i in state) for state in [(0,1,2), (3,4,5), (6,7,8),\n",
    "                                                                    (0,3,6), (1,4,7), (2,5,8), (0,4,8), (2,4,6)])\n",
    "\n",
    "def train_agent(episodes=10000):\n",
    "    agent = TicTacToeQLearning()\n",
    "    for _ in range(episodes):\n",
    "        board, available_moves, player = [0] * 9, list(range(9)), 1\n",
    "        while available_moves:\n",
    "            action = agent.choose_action(board, available_moves)\n",
    "            board[action] = player\n",
    "            agent.state_history.append((board[:], action))\n",
    "            available_moves.remove(action)\n",
    "            if check_winner(board, player):\n",
    "                agent.update_q_table(1 if player == 1 else -1)\n",
    "                break\n",
    "            player *= -1\n",
    "        else:\n",
    "            agent.update_q_table(0)\n",
    "    agent.save_q_table()\n",
    "    return agent\n",
    "\n",
    "def play_interactive_game():\n",
    "    agent = TicTacToeQLearning()\n",
    "    agent.load_q_table()\n",
    "    board, available_moves, player = [0] * 9, list(range(9)), 1\n",
    "    while available_moves:\n",
    "        print_board(board)\n",
    "        move = int(input(\"Enter your move (0-8): \")) if player == 1 else agent.choose_action(board, available_moves)\n",
    "        if move not in available_moves:\n",
    "            continue\n",
    "        print(f\"AI chooses: {move}\" if player == -1 else \"\")\n",
    "        board[move], available_moves = player, [m for m in available_moves if m != move]\n",
    "        if check_winner(board, player):\n",
    "            print_board(board)\n",
    "            print(\"Player 1 wins!\" if player == 1 else \"AI wins!\")\n",
    "            return\n",
    "        player *= -1\n",
    "    print_board(board)\n",
    "    print(\"It's a draw!\")\n",
    "\n",
    "def print_board(board):\n",
    "    symbols = {1: 'X', -1: 'O', 0: ' '}\n",
    "    print(\"\\n\".join([\" | \".join(symbols[board[i]] for i in range(j, j+3)) for j in range(0, 9, 3)]), \"\\n\")\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    train_agent()\n",
    "    print(\"Training Complete! Q-Table Saved.\")\n",
    "    play_interactive_game()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9a55308-bd23-442e-acc0-953c7532b92a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
