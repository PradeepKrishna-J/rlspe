{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "67ac71fe-9ba2-4a78-bfbe-dd09d8ffc827",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GridWorld:\n",
    "    def __init__(self, rows, cols, goal_state, step_reward=0, goal_reward=1):\n",
    "        self.rows = rows\n",
    "        self.cols = cols\n",
    "        self.goal_state = goal_state\n",
    "        self.step_reward = step_reward\n",
    "        self.goal_reward = goal_reward\n",
    "        self.actions = ['up', 'down', 'left', 'right']\n",
    "        self.states = [(i, j) for i in range(rows) for j in range(cols)]\n",
    "\n",
    "    def get_next_state(self, state, action):\n",
    "        if state == self.goal_state:\n",
    "            return state\n",
    "        i, j = state\n",
    "        if action == 'up':\n",
    "            i = max(i - 1, 0)\n",
    "        elif action == 'down':\n",
    "            i = min(i + 1, self.rows - 1)\n",
    "        elif action == 'left':\n",
    "            j = max(j - 1, 0)\n",
    "        elif action == 'right':\n",
    "            j = min(j + 1, self.cols - 1)\n",
    "        return (i, j)\n",
    "\n",
    "    def get_reward(self, state, action, next_state):\n",
    "        return self.goal_reward if next_state == self.goal_state else self.step_reward\n",
    "\n",
    "    def transition_model(self, state, action):\n",
    "        next_state = self.get_next_state(state, action)\n",
    "        return [(1.0, next_state)]  # deterministic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a2420f31-7b24-4785-88af-6853833993d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def value_iteration(states, actions, transition_model, rewards, gamma=0.9, theta=1e-6):\n",
    "    V = {s: 0 for s in states}\n",
    "    policy = {s: None for s in states}\n",
    "    while True:\n",
    "        delta = 0\n",
    "        for s in states:\n",
    "            best_action = None\n",
    "            best_value = float('-inf')\n",
    "            for a in actions:\n",
    "                q = sum(p * (rewards(s, a, s_) + gamma * V[s_]) for p, s_ in transition_model(s, a))\n",
    "                if q > best_value:\n",
    "                    best_value = q\n",
    "                    best_action = a\n",
    "            delta = max(delta, abs(V[s] - best_value))\n",
    "            V[s] = best_value\n",
    "            policy[s] = best_action\n",
    "        if delta < theta:\n",
    "            break\n",
    "    return V, policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2cd55a4b-395a-4964-8d69-f0dbbcbec26e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def policy_iteration(states, actions, transition_model, rewards, gamma=0.9, theta=1e-6):\n",
    "    policy = {s: actions[0] for s in states}\n",
    "    V = {s: 0 for s in states}\n",
    "    while True:\n",
    "        # Policy Evaluation\n",
    "        while True:\n",
    "            delta = 0\n",
    "            for s in states:\n",
    "                a = policy[s]\n",
    "                v = V[s]\n",
    "                V[s] = sum(p * (rewards(s, a, s_) + gamma * V[s_]) for p, s_ in transition_model(s, a))\n",
    "                delta = max(delta, abs(v - V[s]))\n",
    "            if delta < theta:\n",
    "                break\n",
    "        # Policy Improvement\n",
    "        policy_stable = True\n",
    "        for s in states:\n",
    "            old_action = policy[s]\n",
    "            best_action = max(actions, key=lambda a: sum(\n",
    "                p * (rewards(s, a, s_) + gamma * V[s_]) for p, s_ in transition_model(s, a)))\n",
    "            policy[s] = best_action\n",
    "            if old_action != best_action:\n",
    "                policy_stable = False\n",
    "        if policy_stable:\n",
    "            break\n",
    "    return V, policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f85629b2-4de4-4f19-b8b0-165c63739569",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Value Iteration\n",
      "Optimal Policy:\n",
      "(0, 0): down\n",
      "(0, 1): down\n",
      "(1, 0): right\n",
      "(1, 1): None\n",
      "\n",
      "State Values:\n",
      "(0, 0): 91.00\n",
      "(0, 1): 100.00\n",
      "(1, 0): 100.00\n",
      "(1, 1): 100.00\n",
      "\n",
      "Policy Iteration\n",
      "Optimal Policy:\n",
      "(0, 0): down\n",
      "(0, 1): down\n",
      "(1, 0): right\n",
      "(1, 1): None\n",
      "\n",
      "State Values:\n",
      "(0, 0): 91.00\n",
      "(0, 1): 100.00\n",
      "(1, 0): 100.00\n",
      "(1, 1): 100.00\n"
     ]
    }
   ],
   "source": [
    "\n",
    "env = GridWorld(rows=2, cols=2, goal_state=(1, 1), step_reward=1, goal_reward=10)\n",
    "states = env.states\n",
    "actions = env.actions\n",
    "transition_model = env.transition_model\n",
    "rewards = env.get_reward\n",
    "goal = env.goal_state\n",
    "\n",
    "\n",
    "V, policy = value_iteration(states, actions, transition_model, rewards)\n",
    "policy[goal] = None\n",
    "print(\"Value Iteration\\nOptimal Policy:\")\n",
    "for s in sorted(policy):\n",
    "    print(f\"{s}: {policy[s]}\")\n",
    "print(\"\\nState Values:\")\n",
    "for s in sorted(V):\n",
    "    print(f\"{s}: {V[s]:.2f}\")\n",
    "\n",
    "\n",
    "V, policy = policy_iteration(states, actions, transition_model, rewards)\n",
    "policy[goal] = None\n",
    "print(\"\\nPolicy Iteration\\nOptimal Policy:\")\n",
    "for s in sorted(policy):\n",
    "    print(f\"{s}: {policy[s]}\")\n",
    "print(\"\\nState Values:\")\n",
    "for s in sorted(V):\n",
    "    print(f\"{s}: {V[s]:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a93a4e97-aa74-41f1-a83a-fe8b25f44ba0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
